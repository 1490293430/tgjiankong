
# monitor_async.py
import os
import json
import re
import asyncio
from datetime import datetime
from typing import List, Optional, Dict, Any
import psutil
import logging
import signal

from telethon import TelegramClient, events
from telethon.sessions import StringSession
import aiohttp
import motor.motor_asyncio
from mongo_index_init import ensure_indexes

# -----------------------
# é…ç½®ï¼ˆENV æˆ–é»˜è®¤ï¼‰
# -----------------------
CONFIG_PATH = os.getenv("CONFIG_PATH", "/app/config.json")
MONGO_URL = os.getenv("MONGO_URL", "mongodb://mongo:27017")
MONGO_DBNAME = os.getenv("MONGO_DBNAME", "tglogs")
API_URL = os.getenv("API_URL", "http://api:3000")
ENV_API_ID = int(os.getenv("API_ID", "0"))
ENV_API_HASH = os.getenv("API_HASH", "")
SESSION_PATH = os.getenv("SESSION_PATH", "/app/session/telegram")
SESSION_STRING = os.getenv("SESSION_STRING", "").strip()

# å¹¶å‘é™åˆ¶ï¼ˆå¯è°ƒï¼‰
AI_CONCURRENCY = int(os.getenv("AI_CONCURRENCY", "2"))
ALERT_CONCURRENCY = int(os.getenv("ALERT_CONCURRENCY", "4"))

# config reload interval (ç§’) - å¢åŠ åˆ°10ç§’ä»¥å‡å°‘CPUå¼€é”€
CONFIG_RELOAD_INTERVAL = float(os.getenv("CONFIG_RELOAD_INTERVAL", "10.0"))

# -----------------------
# æ—¥å¿—
# -----------------------
logging.basicConfig(level=logging.INFO, format="%(asctime)s [%(levelname)s] %(message)s")
logger = logging.getLogger("tg_monitor")

# -----------------------
# å…¨å±€èµ„æºï¼ˆå¼‚æ­¥å®‰å…¨ï¼‰
# -----------------------
mongo_client = motor.motor_asyncio.AsyncIOMotorClient(MONGO_URL)
db = mongo_client[MONGO_DBNAME]
logs_collection = db["logs"]

# aiohttp session will be created on loop start
http_session: Optional[aiohttp.ClientSession] = None

# config cache and compiled regex
CONFIG_CACHE: Dict[str, Any] = {}
CONFIG_MTIME = 0.0
COMPILED_ALERT_REGEX: List[re.Pattern] = []

# async semaphores to limit concurrency for heavy tasks
ai_semaphore = asyncio.Semaphore(AI_CONCURRENCY)
alert_semaphore = asyncio.Semaphore(ALERT_CONCURRENCY)

# shutdown event
SHUTDOWN = asyncio.Event()


# CPUç›‘æ§ - ä½¿ç”¨ç¼“å­˜å‡å°‘å¼€é”€ï¼Œé¿å…é¢‘ç¹è°ƒç”¨å¯¼è‡´CPUå³°å€¼
_cpu_process = None
_cpu_last_check = 0
_cpu_check_interval = 10.0  # æ¯10ç§’æœ€å¤šæ£€æŸ¥ä¸€æ¬¡

def log_cpu_usage(tag=""):
    """è®°å½•CPUä½¿ç”¨ç‡ï¼Œä½†é™åˆ¶è°ƒç”¨é¢‘ç‡ä»¥é¿å…è‡ªèº«æ¶ˆè€—è¿‡å¤šCPU"""
    global _cpu_process, _cpu_last_check
    import time
    
    current_time = time.time()
    # é™åˆ¶CPUç›‘æ§é¢‘ç‡ï¼Œé¿å…é¢‘ç¹è°ƒç”¨å¯¼è‡´CPUå³°å€¼
    if current_time - _cpu_last_check < _cpu_check_interval:
        return
    
    try:
        if _cpu_process is None:
            _cpu_process = psutil.Process(os.getpid())
        # ä½¿ç”¨interval=0.1è€Œä¸æ˜¯Noneï¼Œå‡å°‘å¼€é”€
        cpu = _cpu_process.cpu_percent(interval=0.1)
        logger.info(f"[CPUç›‘æ§] {tag} å½“å‰è¿›ç¨‹CPUå ç”¨: {cpu}%")
        _cpu_last_check = current_time
    except Exception:
        pass  # å¿½ç•¥CPUç›‘æ§é”™è¯¯ï¼Œé¿å…å½±å“ä¸»æµç¨‹


# -----------------------
# default config helper
# -----------------------
def default_config():
    return {
        "telegram": {"api_id": ENV_API_ID or 0, "api_hash": ENV_API_HASH or ""},
        "keywords": [],
        "channels": [],
        "alert_keywords": [],
        "alert_regex": [],
        "alert_target": "me",
        "log_all_messages": False,
        "ai_analysis": {
            "ai_trigger_enabled": False,
            "ai_trigger_users": []
        }
    }


# -----------------------
# async-safe config loader (only reloads when file mtime changes)
# -----------------------
def load_config_sync():
    """Synchronous file read + json load but called rarely by background task.
       We cache result in CONFIG_CACHE for message handler to use without IO.
    """
    global CONFIG_CACHE, CONFIG_MTIME, COMPILED_ALERT_REGEX
    try:
        if not os.path.exists(CONFIG_PATH):
            CONFIG_CACHE = default_config()
            CONFIG_MTIME = 0.0
            COMPILED_ALERT_REGEX = []
            logger.warning("é…ç½®æ–‡ä»¶ä¸å­˜åœ¨: %sï¼Œä½¿ç”¨é»˜è®¤é…ç½®", CONFIG_PATH)
            return

        mtime = os.path.getmtime(CONFIG_PATH)
        if CONFIG_CACHE and mtime == CONFIG_MTIME:
            return  # no change

        with open(CONFIG_PATH, "r", encoding="utf-8") as f:
            cfg = json.load(f)

        # normalize fields with defaults
        base = default_config()
        base.update(cfg or {})
        CONFIG_CACHE = base
        CONFIG_MTIME = mtime

        # compile regex patterns
        patterns = CONFIG_CACHE.get("alert_regex", []) or []
        COMPILED_ALERT_REGEX = []
        for p in patterns:
            try:
                COMPILED_ALERT_REGEX.append(re.compile(p, re.IGNORECASE))
            except re.error:
                logger.warning("æ— æ•ˆçš„æ­£åˆ™ï¼Œè·³è¿‡: %s", p)

        logger.info("é…ç½®å·²åŠ è½½/æ›´æ–°ï¼škeywords=%d alert_keywords=%d regex=%d channels=%d",
                    len(CONFIG_CACHE.get("keywords", [])),
                    len(CONFIG_CACHE.get("alert_keywords", [])),
                    len(COMPILED_ALERT_REGEX),
                    len(CONFIG_CACHE.get("channels", [])))
    except Exception as e:
        logger.exception("åŠ è½½é…ç½®å¤±è´¥: %s", e)
        CONFIG_CACHE = default_config()
        COMPILED_ALERT_REGEX = []


async def config_reloader_task():
    """åå°ä»»åŠ¡ï¼šå®šæœŸæ£€æŸ¥é…ç½®æ–‡ä»¶æ˜¯å¦å˜åŒ–å¹¶åŠ è½½ï¼ˆåŒæ­¥ IOï¼Œä½†å¾ˆä½é¢‘ï¼‰"""
    loop = asyncio.get_event_loop()
    while not SHUTDOWN.is_set():
        try:
            # run synchronous loader on loop's executor to avoid blocking event loop if file read is slow
            await loop.run_in_executor(None, load_config_sync)
        except Exception as e:
            logger.exception("é…ç½®é‡è½½ä»»åŠ¡å¼‚å¸¸: %s", e)
        # ä½¿ç”¨asyncio.sleepè€Œä¸æ˜¯waitï¼Œæ›´é«˜æ•ˆ
        await asyncio.sleep(CONFIG_RELOAD_INTERVAL)


# -----------------------
# HTTP helpers (aiohttp)
# -----------------------
async def post_json(url: str, payload: dict, timeout: int = 10) -> Optional[dict]:
    global http_session
    if http_session is None:
        raise RuntimeError("HTTP session not initialized")
    try:
        async with http_session.post(url, json=payload, timeout=timeout) as resp:
            text = await resp.text()
            if resp.status == 200:
                try:
                    return await resp.json()
                except Exception:
                    return {"raw": text}
            else:
                logger.warning("POST %s è¿”å› %s: %s", url, resp.status, text[:200])
                return None
    except asyncio.CancelledError:
        raise
    except Exception as e:
        logger.exception("POST è¯·æ±‚å¤±è´¥: %s %s", url, e)
        return None


# -----------------------
# async DB write
# -----------------------
async def save_log_async(channel, channel_id, sender, message, keywords, message_id):
    try:
        doc = {
            "channel": channel,
            "channelId": str(channel_id),
            "sender": sender,
            "message": message,
            "keywords": keywords if isinstance(keywords, list) else [keywords],
            "time": datetime.utcnow(),
            "messageId": message_id,
            "alerted": bool(keywords),
            "ai_analyzed": False
        }
        res = await logs_collection.insert_one(doc)
        return str(res.inserted_id)
    except Exception as e:
        logger.exception("ä¿å­˜æ—¥å¿—å¤±è´¥: %s", e)
        return None


# -----------------------
# AI åˆ†æï¼ˆå¼‚æ­¥é˜Ÿåˆ—ï¼‰
# -----------------------
async def trigger_ai_analysis_async(sender_id, client, log_id=None):
    # ç§»é™¤é¢‘ç¹çš„CPUç›‘æ§è°ƒç”¨
    # log_cpu_usage("AIåˆ†æå¼€å§‹")
    """é€šè¿‡å¼‚æ­¥ HTTP è°ƒç”¨å†…éƒ¨ AI æ¥å£ï¼Œå¹¶æŠŠç»“æœå‘å›ç»™ç”¨æˆ·ï¼ˆé™åˆ¶å¹¶å‘ï¼‰"""
    async with ai_semaphore:
        try:
            payload = {"trigger_type": "user_message"}
            if log_id:
                payload["log_id"] = log_id
            logger.info("è§¦å‘ AI åˆ†æ: log_id=%s", log_id)
            result = await post_json(f"{API_URL}/api/internal/ai/analyze-now", payload, timeout=120)
            if not result:
                logger.warning("AI åˆ†ææ— ç»“æœ")
                return
            if result.get("success"):
                analysis = result.get("analysis", {})
                summary = (
                    "ğŸ¤– AI åˆ†æç»“æœ\n\n"
                    f"ğŸ“Š åˆ†ææ¶ˆæ¯æ•°: {result.get('message_count', 0)}\n\n"
                    f"æ•´ä½“æƒ…æ„Ÿ: {analysis.get('sentiment', 'unknown')} (score={analysis.get('sentiment_score', 0)})\n\n"
                    f"é£é™©ç­‰çº§: {analysis.get('risk_level', 'unknown')}\n\n"
                    f"æ‘˜è¦:\n{analysis.get('summary', 'æ— ')}\n\n"
                    f"å…³é”®è¯: {', '.join(analysis.get('keywords', []))}"
                )
                try:
                    # å‘é€ç»™ç”¨æˆ·ï¼ˆéé˜»å¡ï¼‰
                    await client.send_message(int(sender_id), summary)
                    logger.info("AI åˆ†æç»“æœå·²å‘é€ç»™ %s", sender_id)
                    return True
                except Exception as e:
                    logger.exception("å‘é€ AI ç»“æœå¤±è´¥: %s", e)
            else:
                logger.warning("AI åˆ†æè¿”å›å¤±è´¥: %s", result.get("error"))
        except Exception as e:
            logger.exception("è§¦å‘ AI åˆ†æå¼‚å¸¸: %s", e)
        return False


# -----------------------
# å‘Šè­¦å‘é€ï¼ˆå¼‚æ­¥ï¼‰
# -----------------------
async def send_alert_async(keyword, message, sender, channel, channel_id, message_id):
    async with alert_semaphore:
        payload = {
            "keyword": keyword,
            "message": message,
            "from": sender,
            "channel": channel,
            "channelId": str(channel_id),
            "messageId": message_id
        }
        logger.info("å‘é€å‘Šè­¦åˆ° API: %s", keyword)
        result = await post_json(f"{API_URL}/api/alert/push", payload, timeout=10)
        if result is not None:
            logger.info("å‘Šè­¦å‘é€æˆåŠŸ: %s", keyword)
        else:
            logger.warning("å‘Šè­¦å‘é€å¤±è´¥: %s", keyword)


# -----------------------
# æ¶ˆæ¯å¤„ç†å™¨ï¼ˆéé˜»å¡ / è½»é‡ï¼‰
# -----------------------
async def message_handler(event, client):
    # ç§»é™¤é¢‘ç¹çš„CPUç›‘æ§è°ƒç”¨ï¼Œé¿å…æ¯æ¡æ¶ˆæ¯éƒ½è§¦å‘CPUæ£€æŸ¥å¯¼è‡´å³°å€¼
    # log_cpu_usage("æ¶ˆæ¯å¤„ç†å¼€å§‹")
    try:
        # use cached config only (no IO here)
        config = CONFIG_CACHE or default_config()
        log_all = bool(config.get("log_all_messages", False))

        text = event.raw_text or ""
        if not text:
            return

        chat = await event.get_chat()
        channel_id = str(chat.id)
        channel_name = getattr(chat, "title", None) or getattr(chat, "username", None) or "Unknown"

        # check channel filter
        monitored_channels = config.get("channels", []) or []
        if monitored_channels and channel_id not in monitored_channels:
            return

        # sender info
        sender_entity = None
        try:
            sender_entity = await event.get_sender()
        except Exception:
            sender_entity = None

        sender = "Unknown"
        if sender_entity:
            first_name = getattr(sender_entity, "first_name", None)
            last_name = getattr(sender_entity, "last_name", None)
            username = getattr(sender_entity, "username", None)
            full_name = " ".join([n for n in [first_name, last_name] if n]) if (first_name or last_name) else None
            if full_name:
                sender = f"{full_name} (@{username})" if username else full_name
            elif username:
                sender = f"@{username}"
            else:
                sender = str(getattr(sender_entity, "id", "Unknown"))
        else:
            sid = getattr(event, "sender_id", None)
            sender = str(sid) if sid else channel_name

        sender_id = None
        if sender_entity:
            sender_id = getattr(sender_entity, "id", None)
        if not sender_id:
            sender_id = getattr(event, "sender_id", None)

        # ai trigger users normalize
        ai_trigger_enabled = config.get("ai_analysis", {}).get("ai_trigger_enabled", False)
        ai_trigger_users = config.get("ai_analysis", {}).get("ai_trigger_users", []) or []
        if isinstance(ai_trigger_users, str):
            ai_trigger_users = [u.strip() for u in ai_trigger_users.splitlines() if u.strip()]

        is_trigger_user = False
        if ai_trigger_enabled and ai_trigger_users and sender_id:
            full_name = None
            if sender_entity:
                first_name = getattr(sender_entity, "first_name", None)
                last_name = getattr(sender_entity, "last_name", None)
                full_name = " ".join([n for n in [first_name, last_name] if n]) if (first_name or last_name) else None

            sender_triggers = [
                str(sender_id),
                f"@{getattr(sender_entity, 'username', '')}" if sender_entity and getattr(sender_entity, "username", None) else None,
                full_name,
                sender
            ]
            sender_triggers = [str(s) for s in sender_triggers if s]
            for trigger in ai_trigger_users:
                if str(trigger).strip() in sender_triggers:
                    is_trigger_user = True
                    break

        # keyword checks (cheap)
        matched_keywords = [k for k in (config.get("keywords") or []) if k.lower() in text.lower()]

        # alert keywords (first-match)
        alert_keyword = None
        for keyword in (config.get("alert_keywords") or []):
            if keyword.lower() in text.lower():
                alert_keyword = keyword
                matched_keywords.append(keyword)
                break

        # compiled regex (precompiled at config load)
        if not alert_keyword:
            for pattern in COMPILED_ALERT_REGEX:
                if pattern.search(text):
                    alert_keyword = pattern.pattern
                    matched_keywords.append(f"regex:{pattern.pattern}")
                    break

        # save log if needed (async)
        if matched_keywords or log_all:
            log_id = await save_log_async(channel_name, channel_id, sender, text, matched_keywords or [], event.id)
            if matched_keywords:
                logger.info("ç›‘æ§è§¦å‘ | %s | %s", channel_name, matched_keywords)
            elif log_all:
                logger.info("å·²è®°å½•æ¶ˆæ¯ï¼ˆå…¨é‡ï¼‰| %s", channel_name)

            # trigger AI analysis (async, limited)
            if is_trigger_user and log_id:
                # schedule but don't await; concurrency controlled inside function
                asyncio.create_task(trigger_ai_analysis_async(sender_id, client, log_id))

            # send alert (async)
            if alert_keyword:
                asyncio.create_task(send_alert_async(alert_keyword, text, sender, channel_name, channel_id, event.id))

                # send telegram alert message (non-blocking)
                try:
                    target = (config.get("alert_target") or "me").strip() or "me"
                    def _normalize_target(t):
                        ts = str(t).strip()
                        if (ts.isdigit()) or (ts.startswith("-") and ts[1:].isdigit()):
                            try:
                                return int(ts)
                            except Exception:
                                return ts
                        return ts
                    target_id = _normalize_target(target)
                    alert_message = (
                        f"âš ï¸ å…³é”®è¯å‘Šè­¦è§¦å‘\n\næ¥æºï¼š{channel_name} ({channel_id})\nå‘é€è€…ï¼š{sender}\nå…³é”®è¯ï¼š{alert_keyword}\næ—¶é—´ï¼š{datetime.utcnow().strftime('%Y-%m-%d %H:%M:%S')}\n\næ¶ˆæ¯å†…å®¹ï¼š\n{text[:500]}{'...' if len(text) > 500 else ''}\n"
                    )
                    await client.send_message(target_id, alert_message)
                    logger.info("å‘Šè­¦å·²å‘é€åˆ° Telegram: %s", target)
                except Exception:
                    logger.exception("å‘é€ Telegram å‘Šè­¦å¤±è´¥")
    except Exception:
        logger.exception("å¤„ç†æ¶ˆæ¯å¤±è´¥")
    # ç§»é™¤é¢‘ç¹çš„CPUç›‘æ§è°ƒç”¨ï¼Œé¿å…æ¯æ¡æ¶ˆæ¯éƒ½è§¦å‘CPUæ£€æŸ¥å¯¼è‡´å³°å€¼
    # log_cpu_usage("æ¶ˆæ¯å¤„ç†ç»“æŸ")


# -----------------------
# main å¯åŠ¨
# -----------------------
async def main():

    global http_session

    # è‡ªåŠ¨å»ºç«‹ Mongo ç´¢å¼•ï¼ˆå¦‚æœä¸å­˜åœ¨ï¼‰
    ensure_indexes()

    # initial config load (sync call on startup)
    await asyncio.get_event_loop().run_in_executor(None, load_config_sync)

    cfg = CONFIG_CACHE or default_config()
    cfg_api_id = int(str(cfg.get("telegram", {}).get("api_id", ENV_API_ID or 0)) or 0)
    cfg_api_hash = str(cfg.get("telegram", {}).get("api_hash", ENV_API_HASH or ""))

    if cfg_api_id == 0 or not cfg_api_hash:
        logger.error("æœªé…ç½® API_ID/API_HASHï¼Œè¯·åœ¨é…ç½®æ–‡ä»¶æˆ–ç¯å¢ƒå˜é‡ä¸­å¡«å†™")
        return

    # create aiohttp session
    http_session = aiohttp.ClientSession()

    # create telethon client
    if SESSION_STRING:
        client = TelegramClient(StringSession(SESSION_STRING), cfg_api_id, cfg_api_hash)
    else:
        client = TelegramClient(SESSION_PATH, cfg_api_id, cfg_api_hash)

    await client.start()
    client.add_event_handler(lambda e: message_handler(e, client), events.NewMessage())
    me = await client.get_me()
    logger.info("å·²ç™»å½•ä¸º: %s (ID: %s)", getattr(me, "username", None) or getattr(me, "first_name", None), me.id)

    # start config reloader background task
    reloader = asyncio.create_task(config_reloader_task())

    logger.info("Telegram ç›‘å¬æœåŠ¡å·²å¯åŠ¨ï¼Œç­‰å¾…æ¶ˆæ¯...")

    # run until disconnected or shutdown requested
    try:
        await client.run_until_disconnected()
    finally:
        SHUTDOWN.set()
        reloader.cancel()
        await http_session.close()


# graceful shutdown
def _signal_handler(signame):
    logger.info("æ”¶åˆ°é€€å‡ºä¿¡å· %sï¼Œå‡†å¤‡å…³é—­...", signame)
    SHUTDOWN.set()


if __name__ == "__main__":
    loop = asyncio.get_event_loop()
    for s in (signal.SIGINT, signal.SIGTERM):
        try:
            loop.add_signal_handler(s, lambda s=s: _signal_handler(s))
        except NotImplementedError:
            # Windows ä¸Š loop.add_signal_handler å¯èƒ½ä¸å¯ç”¨
            pass
    try:
        loop.run_until_complete(main())
    except Exception:
        logger.exception("æœåŠ¡å¼‚å¸¸é€€å‡º")
    finally:
        logger.info("æœåŠ¡å·²ç»ˆæ­¢")
